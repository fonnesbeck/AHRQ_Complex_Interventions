{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: right\" src=\"https://www.mc.vanderbilt.edu/documents/lmsa/images/VMS_Logo.png\">\n",
    "\n",
    "# Bayesian Meta-analysis Webinar\n",
    "\n",
    "### Christopher Fonnesbeck, Vanderbilt University School of Medicine\n",
    "\n",
    "#### 28 May 2015"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The primary goal of this presentation is to give an overview on Bayesian inference, and in particular, on how to employ **probabilistic programming** to apply Bayesian methods to meta-analysis. Though this approach to statistical modeling has become more prevalent in the past two decades, and though it has several strengths that make it ideal for meta-analytic modeling, one of the largest obstacles for widespread adoption is the requirement for proficiency in computational methods in order to adopt them. The same off-the-shelf software that is used to conduct classical or frequentist analyses are generally not capable of running Bayesian analysis well.\n",
    "\n",
    "Hence, in the next hour I will provide a link between the *theory* of Bayesian statistics and the *practice* of building Bayesian models, using probabilistic programming. The outline is as follows:\n",
    "\n",
    "### 1. Introduction to Bayesian Statistical Analysis\n",
    "\n",
    "Incase you are poorly acquainted with the Bayesian approach to statistical analysis, I will provide a very brief overview, with links to additional, more comprehensive reference material. This is intended to motivate the use of probabilistic programming tools for conducting meta-analysis.\n",
    "\n",
    "### 2. A Primer on Programming using Python\n",
    "\n",
    "Applying Bayesian methods to analyzing data effectively requires being able to write high-level software programs. While adding a level of complexity to the analysis procedure, this typically results in a more powerful avenue for analyzing data. The good news is there are several scientific programming languages available today that make coding and analysis much easier than with the previous generation of tools. We will learn the basics of these languages, Python, sufficiently to build and run a simple model.\n",
    "\n",
    "### 3. Using Probabilistic Programming to Construct Bayesian Models for Meta-analysis\n",
    "\n",
    "With theory in one hand and a powerful programming language in another, we will employ the probabilistic progrmaming paradigm to specify a meta-analysis. This will be done using a Python data analysis package called `PyMC`. We will step through the preparation of the data, encoding the model in software, then running the model and inspecting the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Webinar materials\n",
    "\n",
    "This webinar is presented using an [IPython Notebook](http://ipython.org/notebook.html), an HTML-based, interactive programming environment for the Python programming language that allows text and other media to be integrated with code. I have placed the notebooks, which can be run interactively or viewed as a static web page, on a GitHub repository. It can be viewed or downloaded here:\n",
    "\n",
    "[https://github.com/fonnesbeck/AHRQ_Complex_Interventions](https://github.com/fonnesbeck/AHRQ_Complex_Interventions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Statistical Analysis\n",
    "\n",
    "Though many of you will have taken a statistics course or two during your undergraduate (or graduate) education, most of those who have will likely not have had a course in *Bayesian* statistics. Most introductory courses, particularly for non-statisticians, still do not cover Bayesian methods at all, except perhaps to derive Bayes' formula as a trivial rearrangement of the definition of conditional probability. Even today, Bayesian courses are typically tacked onto the curriculum, rather than being integrated into the program.\n",
    "\n",
    "In fact, Bayesian statistics is not just a particular method, or even a class of methods; it is an entirely different paradigm for doing statistical analysis.\n",
    "\n",
    "> Practical methods for making inferences from data using probability models for quantities we observe and about which we wish to learn. *-- Gelman et al. 2013*\n",
    "\n",
    "A Bayesian model is described by parameters, uncertainty in those parameters is described using probability distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All conclusions from Bayesian statistical procedures are stated in terms of *probability statements*\n",
    "\n",
    "![](images/prob_model.png)\n",
    "\n",
    "This confers several benefits to the analyst, including:\n",
    "\n",
    "- ease of interpretation, summarization of uncertainty\n",
    "- can incorporate uncertainty in parent parameters\n",
    "- easy to calculate summary statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian vs Frequentist Statistics: What's the difference?\n",
    "\n",
    "![can of worms](images/can-of-worms.jpg)\n",
    "\n",
    "Any statistical paradigm, Bayesian or otherwise, involves at least the following: \n",
    "\n",
    "1. Some **unknown quantities** about which we are interested in learning or testing. We call these *parameters*.\n",
    "2. Some **data** which have been observed, and hopefully contain information about the parameters.\n",
    "3. One or more **models** that relate the data to the parameters, and is the instrument that is used to learn.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Frequentist World View\n",
    "\n",
    "![Fisher](images/fisher.png)\n",
    "\n",
    "- The data that have been observed are considered **random**, because they are realizations of random processes, and hence will vary each time one goes to observe the system.\n",
    "- Model parameters are considered **fixed**. The parameters' values are unknown, but they are fixed, and so we *condition* on them.\n",
    "\n",
    "In mathematical notation, this implies a (very) general model of the following form:\n",
    "\n",
    "<div style=\"font-size:35px\">\n",
    "\\\\[f(y | \\theta)\\\\]\n",
    "</div>\n",
    "\n",
    "Here, the model \\\\(f\\\\) accepts data values \\\\(y\\\\) as an argument, conditional on particular values of \\\\(\\theta\\\\).\n",
    "\n",
    "Frequentist inference typically involves deriving **estimators** for the unknown parameters. Estimators are formulae that return estimates for particular estimands, as a function of data. They are selected based on some chosen optimality criterion, such as *unbiasedness*, *variance minimization*, or *efficiency*.\n",
    "\n",
    "> For example, lets say that we have collected some data on the prevalence of autism spectrum disorder (ASD) in some defined population. Our sample includes \\\\(n\\\\) sampled children, \\\\(y\\\\) of them having been diagnosed with autism. A frequentist estimator of the prevalence \\\\(p\\\\) is:\n",
    "\n",
    "> <div style=\"font-size:25px\">\n",
    "> \\\\[\\hat{p} = \\frac{y}{n}\\\\]\n",
    "> </div>\n",
    "\n",
    "> Why this particular function? Because it can be shown to be unbiased and minimum-variance.\n",
    "\n",
    "It is important to note that new estimators need to be derived for every estimand that is introduced.\n",
    "\n",
    "### The Bayesian World View\n",
    "\n",
    "![Bayes](images/bayes.png)\n",
    "\n",
    "- Data are considered **fixed**. They used to be random, but once they were written into your lab notebook/spreadsheet/database they do not change.\n",
    "- Model parameters themselves may not be random, but Bayesians use probability distribtutions to describe their uncertainty in parameter values, and are therefore treated as **random**. In some cases, it is useful to consider parameters as having been sampled from probability distributions.\n",
    "\n",
    "This implies the following form:\n",
    "\n",
    "<div style=\"font-size:35px\">\n",
    "\\\\[p(\\theta | y)\\\\]\n",
    "</div>\n",
    "\n",
    "This formulation used to be referred to as ***inverse probability***, because it infers from observations to parameters, or from effects to causes.\n",
    "\n",
    "Bayesians do not seek new estimators for every estimation problem they encounter. There is only one estimator for Bayesian inference: **Bayes' Formula**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Inference, in 3 Easy Steps\n",
    "\n",
    "![123](images/123.png)\n",
    "\n",
    "Gelman et al. (2013) describe the process of conducting Bayesian statistical analysis in 3 steps.\n",
    "\n",
    "### Step 1: Specify a probability model\n",
    "\n",
    "As was noted above, Bayesian statistics involves using probability models to solve problems. So, the first task is to *completely specify* the model in terms of probability distributions. This includes everything: unknown parameters, data, covariates, missing data, predictions. All must be assigned some probability density.\n",
    "\n",
    "This step involves making choices.\n",
    "\n",
    "- what is the form of the sampling distribution of the data?\n",
    "- what form best describes our uncertainty in the unknown parameters?\n",
    "\n",
    "### Step 2: Calculate a posterior distribution\n",
    "\n",
    "The mathematical form \\\\(p(\\theta | y)\\\\) that we associated with the Bayesian approach is referred to as a **posterior distribution**.\n",
    "\n",
    "> posterior /pos·ter·i·or/ (pos-tēr´e-er) later in time; subsequent.\n",
    "\n",
    "Why posterior? Because it tells us what we know about the unknown \\\\(\\theta\\\\) *after* having observed \\\\(y\\\\).\n",
    "\n",
    "This posterior distribution is formulated as a function of the probability model that was specified in Step 1. Usually, we can write it down but we cannot calculate it analytically. In fact, the difficulty inherent in calculating the posterior distribution for most models of interest is perhaps the major contributing factor for the lack of widespread adoption of Bayesian methods for data analysis. Various strategies for doing so comprise this tutorial.\n",
    "\n",
    "**But**, once the posterior distribution is calculated, you get a lot for free:\n",
    "\n",
    "- point estimates\n",
    "- credible intervals\n",
    "- quantiles\n",
    "- predictions\n",
    "\n",
    "### Step 3: Check your model\n",
    "\n",
    "Though frequently ignored in practice, it is critical that the model and its outputs be assessed before using the outputs for inference. Models are specified based on assumptions that are largely unverifiable, so the least we can do is examine the output in detail, relative to the specified model and the data that were used to fit the model.\n",
    "\n",
    "Specifically, we must ask:\n",
    "\n",
    "- does the model fit data?\n",
    "- are the conclusions reasonable?\n",
    "- are the outputs sensitive to changes in model structure?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why be Bayesian?\n",
    "\n",
    "At this point, it is worth addressing the question of why one might consider an alternative statistical paradigm to the classical/frequentist statistical approach. After all, it is not always easy to specify a full probabilistic model, nor to obtain output from the model once it is specified. So, why bother?\n",
    "\n",
    "> ... the Bayesian approach is attractive because it is useful. Its usefulness derives in large measure from its simplicity. Its simplicity allows the investigation of far more complex models than can be handled by the tools in the classical toolbox.  \n",
    "*-- Link and Barker 2010*\n",
    "\n",
    "We already noted that there is just one estimator in Bayesian inference, which lends to its ***simplicity***. Moreover, Bayes affords a conceptually simple way of coping with multiple parameters; the use of probabilistic models allows very complex models to be assembled in a modular fashion, by factoring a large joint model into the product of several conditional probabilities.\n",
    "\n",
    "Bayesian statistics is also attractive for its ***coherence***. All unknown quantities for a particular problem are treated as random variables, to be estimated in the same way. Existing knowledge is given precise mathematical expression, allowing it to be integrated with information from the study dataset, and there is formal mechanism for incorporating new information into an existing analysis.\n",
    "\n",
    "Finally, Bayesian statistics confers an advantage in the ***iterpretability*** of analytic outputs. Because models are expressed probabilistically, results can be interpreted probabilistically. Probabilities are easy for users (particularly non-technical users) to understand and apply."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: confidence vs. credible intervals\n",
    "\n",
    "A commonly-used measure of uncertainty for a statistical point estimate in classical statistics is the ***confidence interval***. Most scientists were introduced to the confidence interval during their introductory statistics course(s) in college. Yet, a large number of users mis-interpret the confidence interval.\n",
    "\n",
    "Here is the mathematical definition of a 95% confidence interval for some unknown scalar quantity that we will here call \\\\(\\theta\\\\):\n",
    "\n",
    "<div style=\"font-size:25px\">\n",
    "\\\\[Pr(a(Y) < \\theta < b(Y) | \\theta) = 0.95\\\\]\n",
    "</div>\n",
    "\n",
    "how the endpoints of this interval are calculated varies according to the sampling distribution of \\\\(Y\\\\), but for as an example, the confidence interval for the population mean when \\\\(Y\\\\) is normally distributed is calculated by:\n",
    "\n",
    "\\\\[Pr(\\bar{Y} - 1.96\\frac{\\sigma}{\\sqrt{n}}< \\theta < \\bar{Y} + 1.96\\frac{\\sigma}{\\sqrt{n}}) = 0.95\\\\]\n",
    "\n",
    "It would be tempting to use this definition to conclude that there is a 95% chance \\\\(\\theta\\\\) is between \\\\(a(Y)\\\\) and \\\\(b(Y)\\\\), but that would be a mistake. \n",
    "\n",
    "Recall that for frequentists, unknown parameters are **fixed**, which means there is no probability associated with them being any value except what they are fixed to. Here, the interval itself, and not \\\\(\\theta\\\\) is the random variable. The actual interval calculated from the data is just one possible realization of a random process, and it must be strictly interpreted only in relation to an infinite sequence of identical trials that might be (but never are) conducted in practice.\n",
    "\n",
    "A valid interpretation of the above would be:\n",
    "\n",
    "> If the experiment were repeated an infinite number of times, 95% of the calculated intervals would contain \\\\(\\theta\\\\).\n",
    "\n",
    "This is what the statistical notion of \"confidence\" entails, and this sets it apart from probability intervals.\n",
    "\n",
    "Since they regard unknown parameters as random variables, Bayesians can and do use probability intervals to describe what is known about the value of an unknown quantity. These intervals are commonly known as ***credible intervals***.\n",
    "\n",
    "The definition of a 95% credible interval is:\n",
    "\n",
    "<div style=\"font-size:25px\">\n",
    "\\\\[Pr(a(y) < \\theta < b(y) | Y=y) = 0.95\\\\]\n",
    "</div>\n",
    "\n",
    "Notice that we condition here on the data \\\\(y\\\\) instead of the unknown \\\\(\\theta\\\\). Thus, the endpoints are fixed and the variable is random. \n",
    "\n",
    "We are allowed to interpret this interval as:\n",
    "\n",
    "> There is a 95% chance \\\\(\\theta\\\\) is between \\\\(a\\\\) and \\\\(b\\\\).\n",
    "\n",
    "Hence, the credible interval is a statement of what we know about the value of \\\\(\\theta\\\\) based on the observed data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability\n",
    "\n",
    "> *Misunderstanding of probability may be the greatest of all impediments to scientific literacy.*\n",
    "> — Stephen Jay Gould\n",
    "\n",
    "Because of its reliance on probabilty models, its worth talking a little bit about probability. There are three different ways to define probability, depending on how it is being used.\n",
    "\n",
    "### 1. Classical probability\n",
    "\n",
    "<div style=\"font-size:25px\">\n",
    "\\\\[Pr(X=x) = \\frac{\\text{# x outcomes}}{\\text{# possible outcomes}}\\\\]\n",
    "</div>\n",
    "\n",
    "Classical probability is an assessment of **possible** outcomes of elementary events. Elementary events are assumed to be equally likely.\n",
    "\n",
    "### 2. Frequentist probability\n",
    "\n",
    "<div style=\"font-size:25px\">\n",
    "\\\\[Pr(X=x) = \\lim_{n \\rightarrow \\infty} \\frac{\\text{# times x has occurred}}{\\text{# independent and identical trials}}\\\\]\n",
    "</div>\n",
    "\n",
    "Unlike classical probability, frequentist probability is an EMPIRICAL definition. It is an objective statement desribing events that have occurred.\n",
    "\n",
    "### 3. Subjective probability\n",
    "\n",
    "<div style=\"font-size:25px\">\n",
    "\\\\[Pr(X=x)\\\\]\n",
    "</div>\n",
    "\n",
    "Subjective probability is a measure of one's uncertainty in the value of \\\\(X\\\\). It characterizes the state of knowledge regarding some unknown quantity using probability.\n",
    "\n",
    "It is not associated with long-term frequencies nor with equal-probability events.\n",
    "\n",
    "For example:\n",
    "\n",
    "- X = the true prevalence of diabetes in Austin is < 15%\n",
    "- X = the blood type of the person sitting next to you is type A\n",
    "- X = the Nashville Predators will win next year's Stanley Cup\n",
    "- X = it is raining in Nashville\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes' Formula\n",
    "\n",
    "The goal in Bayesian inference is to calculate the **posterior distribution** of our unknowns:\n",
    "\n",
    "<div style=\"font-size: 150%;\">  \n",
    "\\\\[Pr(\\theta|Y=y)\\\\]\n",
    "</div>\n",
    "\n",
    "This expression is a **conditional probability**. It is the probability of \\\\(\\theta\\\\) *given* the observed values of \\\\(Y=y\\\\).\n",
    "\n",
    "This posterior distribution is calculated using Bayes' formula:\n",
    "\n",
    "![bayes formula](images/bayes_formula.png)\n",
    "\n",
    "The equation expresses how our belief about the value of \\\\(\\theta\\\\), as expressed by the **prior distribution** \\\\(P(\\theta)\\\\) is reallocated following the observation of the data \\\\(y\\\\), as expressed by the posterior distribution the posterior distribution.\n",
    "\n",
    "The innocuous denominator \\\\(P(y)\\\\) cannot be calculated directly, and is actually the expression in the numerator, integrated over all \\\\(\\theta\\\\):\n",
    "\n",
    "<div style=\"font-size: 150%;\">  \n",
    "\\\\[Pr(\\theta|y) = \\frac{Pr(y|\\theta)Pr(\\theta)}{\\int Pr(y|\\theta)Pr(\\theta) d\\theta}\\\\]\n",
    "</div>\n",
    "\n",
    "The intractability of this integral is one of the factors that has contributed to the under-utilization of Bayesian methods by statisticians.\n",
    "\n",
    "### Priors\n",
    "\n",
    "Once considered a controversial aspect of Bayesian analysis, the prior distribution characterizes what is known about an unknown quantity before observing the data from the present study. Thus, it represents the information state of that parameter. It can be used to reflect the information obtained in previous studies, to constrain the parameter to plausible values, or to represent the population of possible parameter values, of which the current study's parameter value can be considered a sample.\n",
    "\n",
    "### Likelihood functions\n",
    "\n",
    "The likelihood represents the information in the observed data, and is used to update prior distributions to posterior distributions. This updating of belief is justified becuase of the **likelihood principle**, which states:\n",
    "\n",
    "> Following observation of \\\\(y\\\\), the likelihood \\\\(L(\\theta|y)\\\\) contains all experimental information from \\\\(y\\\\) about the unknown \\\\(\\theta\\\\).\n",
    "\n",
    "Bayesian analysis satisfies the likelihood principle because the posterior distribution's dependence on the data is only through the likelihood. In comparison, most frequentist inference procedures violate the likelihood principle, because inference will depend on the design of the trial or experiment.\n",
    "\n",
    "## Bayesian Updating\n",
    "\n",
    "![Bayesian updating](http://d.pr/i/1by1M+)\n",
    "*(via [Probabilistic Programming and Bayesian Methods for Hackers](http://camdavidsonpilon.github.io/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/))*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Programming\n",
    "\n",
    "## What is Python?\n",
    "\n",
    "Python is:\n",
    "\n",
    "* a modern, general-purpose programming language\n",
    "* open-source \n",
    "* an *interpreted* language \n",
    "\n",
    "It is often compared to languages like R and Ruby. It offers the power and flexibility of lower level (*i.e.* compiled) languages, without the steep learning curve, and without most of the associated  pitfalls for new or non-expert users. The language is very clean and readable, and it is available for almost every modern computing platform.\n",
    "\n",
    "![python](http://imgs.xkcd.com/comics/python.png)\n",
    "\n",
    "*(via [xkcd](http://imgs.xkcd.com/comics/python.png))*\n",
    "\n",
    "## Why use Python for scientific programming?\n",
    "\n",
    "Python offers a number of advantages to scientists, both for experienced and novice programmers alike:\n",
    "\n",
    "***Powerful and easy to use***  \n",
    "\n",
    "* avoids the power/ease-of-use tradeoff\n",
    "* clean, readable syntax\n",
    "* rich standard library\n",
    "\n",
    "***Interactive***  \n",
    "\n",
    "* run interactively from the command line\n",
    "* run non-interactiely with scripts\n",
    "* IPython notebooks for reproducibility\n",
    "\n",
    "\n",
    "***Extensible***  \n",
    "\n",
    "* useful in mixed-language environments\n",
    "* advanced users can write fast extensions using Fortran, C, or Cython\n",
    "\n",
    "\n",
    "***Third-party modules***  \n",
    "\n",
    "There is a vast body of Python modules created outside the auspices of the Python Software Foundation. These include utilities for database connectivity, mathematics, statistics, and charting/plotting. Some notables include:\n",
    "\n",
    "* `NumPy`: array data structures and array operations.\n",
    "* `SciPy`: set of high level science and engineering modules, including optimization, integration, special functions, signal and image processing, genetic algorithms, ODE solvers, and others.\n",
    "* `Matplotlib`: 2D plotting library for publication-quality figures.\n",
    "* `Pandas`: high-performance, easy-to-use tabular data structures and data analysis tools. In particular, the `DataFrame` class is useful for spreadsheet-like representation and mannipulation of data. Also includes high-level plotting functionality.\n",
    "* `IPython`: enhanced Python shell, designed to increase the efficiency and usability of coding, testing and debugging.\n",
    "\n",
    "***Free and open***  \n",
    "\n",
    "Python is released on all platforms under the GNU public license, meaning that the language and its source is freely distributable. Not only does this keep costs down for scientists and universities operating  under a limited budget, but it also frees programmers from licensing concerns for any software they may develop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "Let's look at some Python code, beginning with the simplest possible operation: assignment of values to variables. Let's create a variable called `weight_kg` (its nice to give your variables meaningful names!) and assign it a particular value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight_kg = 79.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All we have done here is created a \"label\" and bound a particular value to it. We can take a look at the current value of `weight_kg`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79.5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_kg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to know what kind of variable this is, the `type` function will give us this information. We **call** a function by following the function name with parentheses that enclose any relevant **arguments** the function may need to operate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(weight_kg) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may also use the `print` function to report the value of `weight_kg` in a meaningful way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My weight in kilograms is 79.5\n"
     ]
    }
   ],
   "source": [
    "print('My weight in kilograms is', weight_kg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might now use an arithmetic operator on our variable to create a new one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174.9"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_lbs = weight_kg * 2.2\n",
    "\n",
    "weight_lbs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables in Python are **dynamically typed**, which means that unlike many languages you do not have to pre-specify what kind of variable you need; it automatically figures out the type for you. Moreover, if you want to use the variable to hold another kind of variable, you can."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'none of your business!'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_kg = 'none of your business!'\n",
    "\n",
    "weight_kg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(weight_kg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use Python for data analysis, we need a more general data structure, since we will be dealing with entire datasets, and we do not wish to assign each value to individual variables. The simplest such *vector-valued* data structure is the Python **list**, which is specified by surrounding comma-separated value with square braces. \n",
    "\n",
    "Let's look at a list of data, which we will use later in an example analysis. These are the occurrences of deaths during cardiac surgery procedures at 12 different hospitals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "deaths = [2, 18, 8, 46, 8, 13, 9, 31, 14, 8, 29, 24]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may want to know how many items are in this list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(deaths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may wish to look at the first item of the list only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deaths[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The square brackets are used to pass an index (or set of indices) to the list. Notice that the first item is indexed by zero, rather than by one. \n",
    "\n",
    "Or, we may wish to look at the first 4 values of the list only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 18, 8, 46]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deaths[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The colon specifies a sqeuence from a to b by `a:b`. If `a` is omitted, it assumes to begin at the start of the list, and if `b` is omitted, it assumes to end at the end of the list. In fact, one way to generate a copy of the list is to pass it a colon, all by itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 18, 8, 46, 8, 13, 9, 31, 14, 8, 29, 24]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deaths[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use indices to **replace** values in a list, as well as just to look at them. For example, there is an error in this dataset: the number of deaths at the first (index zero!) hospital should be zero rather than two. We can fix this by assigning zero to the indexed element:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "deaths[0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may wish to perform an operation on each of the elements of the data list. The simplest way to do this is to construct a **loop** and execute the operation on each element, in turn. We can do this using a `for` loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "324\n",
      "64\n",
      "2116\n",
      "64\n",
      "169\n",
      "81\n",
      "961\n",
      "196\n",
      "64\n",
      "841\n",
      "576\n"
     ]
    }
   ],
   "source": [
    "for x in deaths:\n",
    "    x2 = x**2\n",
    "    print(x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `for` loop above assigns each of the values in `deaths` to the variable `x` in order from beginning to end. The loop includes any statements after the colon that are indented; there is no need for brackets, as you see in most other programming languages, making the code easy to read.  So, for each element, the value is squared (using the `**` power operator) and assigned to a new variable `x2`, then this value is printed before moving on to the next item in the list.\n",
    "\n",
    "Notice a couple of things here: we did not have to use explicit indexes, counting from zero to eleven, as you might have expected, to obtain each of the values in `deaths` (though we could have!). This is because Python lists are **iterable**, which means control structures like `for` loops know how to extract each element from it, as needed.\n",
    "\n",
    "If we wanted to save these values to a new list, we would have to initialize an empty list and populate it using the `for` loop, using the `append` method for lists. \n",
    "\n",
    "> A **method** is just a function that is associated with a particular Python object\n",
    "\n",
    "Here is what that looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 324, 64, 2116, 64, 169, 81, 961, 196, 64, 841, 576]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize an empty list\n",
    "deaths_squared = []\n",
    "\n",
    "for x in deaths:\n",
    "    deaths_squared.append(x**2)\n",
    "    \n",
    "deaths_squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider what we would have to do in order to calculate the *rate* of mortality for the procedure, by dividing each death count by the number of surgeries performed in each hospital ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "surgeries = [47, 148, 119, 810, 211, 196, 148, 215, 207, 97, 256, 360]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Somehow we would have to iterate, pair-wise, over both lists and divide one element by the other. We could do this with the help of a useful Python function called `zip`, which iterates over two iterables, pair-wise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.12162162162162163,\n",
       " 0.06722689075630252,\n",
       " 0.056790123456790124,\n",
       " 0.037914691943127965,\n",
       " 0.0663265306122449,\n",
       " 0.060810810810810814,\n",
       " 0.14418604651162792,\n",
       " 0.06763285024154589,\n",
       " 0.08247422680412371,\n",
       " 0.11328125,\n",
       " 0.06666666666666667]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "death_rate = []\n",
    "\n",
    "for x,n in zip(deaths, surgeries):\n",
    "    death_rate.append(x/n)\n",
    "    \n",
    "death_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more advanced manipuation of vector-valued variables, it is recommended that we move away from Python's built-in lists to the more capable `ndarray` structure that is provided by the Numpy package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 18,  8, 46,  8, 13,  9, 31, 14,  8, 29, 24])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "\n",
    "deaths_array = numpy.array(deaths)\n",
    "deaths_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surgeries_array = numpy.array(surgeries)\n",
    "type(surgeries_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the many useful features of the Numpy array is that it performs element-wise operations, avoiding the need to explicitly loop over its elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,  324,   64, 2116,   64,  169,   81,  961,  196,   64,  841,\n",
       "        576])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deaths_array**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.12162162,  0.06722689,  0.05679012,  0.03791469,\n",
       "        0.06632653,  0.06081081,  0.14418605,  0.06763285,  0.08247423,\n",
       "        0.11328125,  0.06666667])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deaths_array/surgeries_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probabilistic Programming with PyMC\n",
    "\n",
    "Beyond the basics of Python programming, our goal here is to expose you to **probabilistic programming**, and how it can be used to build Bayesian statistical models.\n",
    "\n",
    "![PPL](http://d.pr/i/16Rz5+)\n",
    "\n",
    "The practical difference between probabilistic programming and standard computer programming is that rather than being able to assign simple numeric values (or other data types) to variables, probabilistic programming allows entire probability distributions to be assigned to variables, and manipulated.\n",
    "\n",
    "***Why is this relevant?*** In Bayesian inference, recall that we are compelled to specify a *full probability model* that assigns probability distributions to all unknown quantities, in a way that represents our current belief in the possible values that they may take. How do we represent this in computer code? Using a probabilistic programming language, we can simply assign a distribution to a variable.\n",
    "\n",
    "For example, consider the mortality rate for infant cardiac surgeries above; since it is a value constrained to be between zero and one, we might use a **beta distribution**.\n",
    "\n",
    "![beta](http://d.pr/i/19sPw+)\n",
    "\n",
    "For example, one choice might be:\n",
    "\n",
    "\\\\[\\text{rate} \\sim \\text{Beta}(1, 1)\\\\]\n",
    "\n",
    "This parameterization assigns equal probability to all possible values on the unit interval. Here are some sample values from a `Beta(1,1)` distribution using Numpy's `random` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "samples = numpy.random.beta(1, 1, size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily look at the distribution of the resulting samples, using `distplot` from the Seaborn package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x10bf69b38>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": [
       "iVBORw0KGgoAAAANSUhEUgAAAekAAAFVCAYAAADLxheZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAALEgAACxIB0t1+/AAAE5lJREFUeJzt3WuM7Pd91/HP7M0n8lnbJT4kCpeaUvErCqQoJU1tiH0S\n",
       "HBGnFzcgFAFRaRBJARP1QiMSVwFxCQ2kuG1albaOi+kDQGBhQA0uAkxru1i0lArFrvnFaUWEhJz6\n",
       "UsdrR3a8O8ODXUebw9mdndmZne/uvF6Pzszsznz11TnnvTPzn/8ORqNRAIB6VhY9AABweSINAEWJ\n",
       "NAAUJdIAUJRIA0BRIg0ARa2N+4LW2puTfKz3/tbW2h9J8okk20leSvIdvfcnW2vvS/L+JC8n+Wjv\n",
       "/VPzHBoAlsGhz6Rbax9McmeSK/au+pEkt/Xe35bk3iR/o7X2miQfSHJ9knck+cHW2vr8RgaA5TDu\n",
       "5e7PJnnXvsvv7r1/eu/Pa0leTPKNSR7qvW/33p9L8niSN8x8UgBYModGuvd+b3Zf2n7l8ueTpLV2\n",
       "Q5LbkvxwkquSfGHftz2f5OqZTwoAS2bse9KXaq29O8mHk7yz9/50a+257Ib6FZtJnj3sPkaj0Wgw\n",
       "GEz60ABwmk0cvoki3Vp7T3YPELvYe38lxL+c5O+11jaSvCrJ1yV55NApB4M8+eTWpLMyoQsXNu15\n",
       "zux4/ux4/uz4ZFy4sDnx9xw50q21lSQ/muRzSe5trY2S/GLv/W+31j6R5KHs/pRwe+/9SxNPAgB8\n",
       "hbGR7r1/LskNexdffcDX3JXkrhnOBQBLz8lMAKAokQaAokQaAIoSaQAoSqQBoCiRBoCiRBoAihJp\n",
       "AChKpAGgKJEGgKJEGgCKEmkAKEqkAaAokQaAokQaAIoa+/ukAZin0aIHyGg0OuIcg3mPwiVEGmDB\n",
       "Hn70iWwPFxfrzSufydYLLx14+9rKINe//rUnOBGvEGmABdsejrKzs7hI7wyz0MfnYN6TBoCiRBoA\n",
       "ihJpAChKpAGgKJEGgKJEGgCKEmkAKEqkAaAokQaAokQaAIoSaQAoSqQBoCiRBoCiRBoAihJpAChK\n",
       "pAGgKJEGgKJEGgCKWlv0AJxVo0UPMIHBogcAuCyRZm4efvSJbA/rxnptZZDrX//aRY8BcCCRZm62\n",
       "h6Ps7NSNNEB13pMGgKJEGgCK8nI3AEdwGt66OnsHgYo0AIdaXRnk4Uc/X/ZA0LN8EOjYSLfW3pzk\n",
       "Y733t7bWfn+Su5MMkzzSe79t72vel+T9SV5O8tHe+6fmNzIAJ82BoItx6HvSrbUPJrkzyRV7V92R\n",
       "5Pbe+01JVlprt7bWXpPkA0muT/KOJD/YWluf48wAsBTGHTj22STv2nf5G3rvD+79+b4kb0/yjUke\n",
       "6r1v996fS/J4kjfMfFIAWDKHRrr3fm+S7X1X7X9XfivJVUk2k3xh3/XPJ7l6VgMCwLKa9MCx4b4/\n",
       "byZ5Nslz2Y31pdcf6sKFzQkfmmksas+j0SibVz6TneH4r12U1ZXk2ms3Mxgc74hQf5fn7yzvuMq/\n",
       "lc3z5w68bWNt9z3p4bDm0dOz+rdc0aSR/h+ttRt77w8kuSXJ/Ul+JclHW2sbSV6V5OuSPDLujp58\n",
       "cmvSWZnQhQubC9zzKFsvvFT6QJPV1UGeemorx/nYxmJ3vBzO/o4X/29l8/y5bD3/4oG3b6yvZKfw\n",
       "gWOz+Ld8Eqb5YXPSSH9/kjv3Dgx7LMk9vfdRa+0TSR7K7oZu771/aeJJAICvMDbSvffPJblh78+P\n",
       "J7l4ma+5K8ldsx4OAJaZ04ICQFEiDQBFiTQAFCXSAFCUSANAUSINAEWJNAAUJdIAUJRIA0BRIg0A\n",
       "RYk0ABQl0gBQlEgDQFEiDQBFiTQAFCXSAFCUSANAUSINAEWJNAAUJdIAUJRIA0BRa4seADjIaNED\n",
       "TGCw6AHgTBJpKOzhR5/I9rBurNdWBrn+9a9d9BhwZok0FLY9HGVnp26kd813vtFoNIPH8Ez/7Kv+\n",
       "72Q6Ig1MbXVlkIcf/fxcn+1vXvlMtl54aarv9Ux/OZzE38PjWlsZ5NsuXjX5981hFmCJzPvZ/s4w\n",
       "p+DVBBbtdLzqNDlHdwNAUSINAEWJNAAUJdIAUJRIA0BRju4GzrjqR/xWn49FEmngzDoNn5+9Ys0L\n",
       "mhxMpIEzrfrnZ7dX6s7G4vkRDgCKEmkAKGohL3fv7AwzHA4X8dBHtrIyiJPyA7BIC4n04//nt/Pr\n",
       "v/HUIh76SNZXB/kmJ+UHYMEWduDYTuGjLVc8gQagAEd3n1rjf8iZze/hnVbdH8K+0vHmnO+OT8sO\n",
       "gXkR6VPs4UefOPTzn8f5PbzHdRo++zmLz9DOc8enYYfAfIn0KTbu85+L/D28p+Wzn8f9DO08d3xa\n",
       "dgjMjx/VAaCoiZ9Jt9bWkvzTJNcl2U7yviQ7Se5OMkzySO/9ttmNCADLaZpn0u9Mstp7/2NJ/m6S\n",
       "v5/kjiS3995vSrLSWrt1hjMCwFKaJtKfSbLWWhskuTrJy0ne2Ht/cO/2+5LcPKP5AGBpTXPg2PNJ\n",
       "fl+S/5Xk1Um+Nclb9t2+ld14AwDHME2kvzfJz/fef6C19ruS/EKSjX23byZ5dtydbJ4/N8VDn4y1\n",
       "1eTaazczGNQ9q8loNMrmlc9kZ8zZVRe154213SOnh8O6O5zVjPPa8TLtcJxpd2yHR3fYjqvMeJDq\n",
       "8yXJ6pSHaU8T6Wey+xJ3shvjtSS/1lq7qff+i0luSXL/uDvZev7FKR76ZKyvDvLUU1upfe7uUbZe\n",
       "eOnQj/9snj+3sD1vrK9kp/ivCJzFjPPc8bLscJzj7NgOj2bcjivMeJjq8yXJ6up0PZkm0j+S5Gda\n",
       "aw8kWU/yoSS/muSTrbX1JI8luWeqaQCAL5s40r33F5K8+zI3XTz2NADAlznj2IHqvmyyq/p8AByX\n",
       "SF/GLM7pPG/O6wxw9on0AY57Tud5c15ngLPP0zEAKEqkAaAokQaAokQaAIoSaQAoSqQBoCiRBoCi\n",
       "RBoAihJpAChKpAGgKJEGgKJEGgCKEmkAKEqkAaAokQaAokQaAIoSaQAoSqQBoCiRBoCiRBoAihJp\n",
       "AChKpAGgKJEGgKJEGgCKEmkAKEqkAaAokQaAokQaAIoSaQAoSqQBoCiRBoCiRBoAihJpAChKpAGg\n",
       "KJEGgKJEGgCKEmkAKEqkAaAokQaAokQaAIoSaQAoam2ab2qtfSjJtyVZT/ITSR5IcneSYZJHeu+3\n",
       "zWpAAFhWEz+Tbq3dlOT63vsNSS4m+b1J7khye+/9piQrrbVbZzolACyhaV7u/pNJHmmt/Zsk/y7J\n",
       "zyV5Y+/9wb3b70ty84zmA4ClNc3L3ddm99nztyT5muyGen/st5JcPe5ONs+fm+KhT8bGerK9M8pw\n",
       "OFj0KAfaWEu2h+NnXNSejzrfIs1qxnnteJl2OM60O7bDoztsx1VmPEj1+ZJkdcojwKaJ9NNJHuu9\n",
       "byf5TGvtxSS/e9/tm0meHXcnW8+/OMVDn4xz6yt5eTjKzs5o0aMcaGN9JTtjZtw8f25hez7KfIs2\n",
       "ixnnueNl2eE4x9mxHR7NuB1XmPEw1edLktXV6X6AmKbtDyV5R5K01l6X5Mok/3nvveokuSXJgwd8\n",
       "LwBwRBM/k+69f6q19pbW2i8nGST5K0n+d5JPttbWkzyW5J6ZTgkAS2iqj2D13j90masvHm8UAGA/\n",
       "JzMBgKJEGgCKEmkAKEqkAaAokQaAokQaAIoSaQAoSqQBoCiRBoCiRBoAihJpAChKpAGgKJEGgKJE\n",
       "GgCKEmkAKEqkAaAokQaAokQaAIoSaQAoSqQBoCiRBoCiRBoAihJpAChKpAGgKJEGgKJEGgCKEmkA\n",
       "KEqkAaAokQaAokQaAIoSaQAoSqQBoCiRBoCiRBoAihJpAChKpAGgKJEGgKJEGgCKEmkAKEqkAaAo\n",
       "kQaAokQaAIoSaQAoam3ab2yt/c4k/z3JzUl2ktydZJjkkd77bTOZDgCW2FTPpFtra0l+MskX9666\n",
       "I8ntvfebkqy01m6d0XwAsLSmfbn7h5L84yT/N8kgyRt77w/u3XZfdp9dAwDHMHGkW2vfmeS3eu//\n",
       "MbuBvvR+tpJcffzRAGC5TfOe9HuTDFtrb0/y9Ul+NsmFfbdvJnl23J1snj83xUOfjI31ZHtnlOFw\n",
       "MP6LF2RjLdkejp9xUXs+6nyLNKsZ57XjZdrhONPu2A6P7rAdV5nxINXnS5LVKV+3njjSe+87J0la\n",
       "a/cn+ctJPt5au7H3/kCSW5LcP+5+tp5/cdKHPjHn1lfy8nCUnZ3Rokc50Mb6SnbGzLh5/tzC9nyU\n",
       "+RZtFjPOc8fLssNxjrNjOzyacTuuMONhqs+XJKur0/0AMfXR3Zf4/iR3ttbWkzyW5J4Z3S8ALK1j\n",
       "Rbr3/rZ9Fy8ebxQAYD8nMwGAokQaAIoSaQAoSqQBoCiRBoCiRBoAihJpAChKpAGgKJEGgKJEGgCK\n",
       "EmkAKEqkAaAokQaAokQaAIoSaQAoSqQBoCiRBoCiRBoAihJpAChKpAGgKJEGgKJEGgCKEmkAKEqk\n",
       "AaAokQaAokQaAIoSaQAoSqQBoCiRBoCiRBoAihJpAChKpAGgKJEGgKJEGgCKEmkAKEqkAaAokQaA\n",
       "okQaAIoSaQAoSqQBoCiRBoCiRBoAihJpAChqbdJvaK2tJfmZJNcl2Ujy0SS/nuTuJMMkj/Teb5vd\n",
       "iACwnKZ5Jv2eJE/13m9M8o4kP57kjiS3995vSrLSWrt1hjMCwFKaJtL/MslH9v68mmQ7yRt77w/u\n",
       "XXdfkptnMBsALLWJX+7uvX8xSVprm0n+VZIfSPJD+75kK8nVM5kOAJbYxJFOktba70nyr5P8eO/9\n",
       "X7TW/uG+mzeTPDvuPjbPn5vmoU/ExnqyvTPKcDhY9CgH2lhLtofjZ1zUno863yLNasZ57XiZdjjO\n",
       "tDu2w6M7bMdVZjxI9fmSZHXKw7SnOXDsNUn+Q5Lbeu//Ze/qX2ut3dh7fyDJLUnuH3c/W8+/OOlD\n",
       "n5hz6yt5eTjKzs5o0aMcaGN9JTtjZtw8f25hez7KfIs2ixnnueNl2eE4x9mxHR7NuB1XmPEw1edL\n",
       "ktXV6X6AmOaZ9IeTXJPkI621v5lklOS7k/xYa209yWNJ7plqGgDgy6Z5T/p7knzPZW66eOxpAIAv\n",
       "czITAChKpAGgKJEGgKJEGgCKEmkAKEqkAaAokQaAokQaAIoSaQAoSqQBoCiRBoCiRBoAihJpAChK\n",
       "pAGgKJEGgKJEGgCKEmkAKEqkAaAokQaAokQaAIoSaQAoSqQBoCiRBoCiRBoAihJpAChKpAGgKJEG\n",
       "gKJEGgCKEmkAKEqkAaAokQaAokQaAIoSaQAoSqQBoCiRBoCiRBoAihJpAChKpAGgKJEGgKJEGgCK\n",
       "EmkAKEqkAaAokQaAotZmdUettUGSn0jy9UleTPKXeu+/Oav7B4BlM8tn0t+e5Ire+w1JPpzkjhne\n",
       "NwAsnVlG+o8n+fkk6b3/tyR/dIb3DQBLZ2Yvdye5KskX9l3ebq2t9N6Hl37huY3VvPqqK2b40LO1\n",
       "vjbIb299adFjHGptZZDBmK9ZXUlWV8d91XwcZb5Fm8WM89zxsuxwnOPs2A6PZtyOK8x4mOrzJbsz\n",
       "TvV9M5zhuSSb+y5fNtBJct3rrhlc97prZvjQAHD2zPLl7l9K8s4kaa19U5JPz/C+AWDpzPKZ9L1J\n",
       "3t5a+6W9y++d4X0DwNIZjEajRc8AAFyGk5kAQFEiDQBFiTQAFCXSAFDULI/u/v+MO593a+1bk3wk\n",
       "yctJ/knv/ZPznOcsOsKO/2yS787ujj/de/+rCxn0FDvqeelbaz+V5One++0nPOKZcIS/y29K8o/2\n",
       "Lj6R5D2999pnHSrmCDv+80m+L8l2dv9P/smFDHoGtNbenORjvfe3XnL9RN2b9zPpA8/n3Vpb27t8\n",
       "c5KLSd7fWrsw53nOosN2fC7J30lyU+/9LUmuaa19y2LGPNXGnpe+tfZdSf7QSQ92xozb808n+c7e\n",
       "+43ZPQXxV5/wfGfBuB1/PMnbsnua57/eWrv6hOc7E1prH0xyZ5IrLrl+4u7NO9KHnc/7DyZ5vPf+\n",
       "XO/95SQPJblxzvOcRYft+KUkN/TeX9q7vJbdn56ZzKHnpW+tXZ/kTUl+6uRHO1MO3HNr7Q8keTrJ\n",
       "97XWfiHJ7+i9P76IIU+5cb9j4X8m+aokr9q77DO60/lskndd5vqJuzfvSF/2fN4H3LaVxE9tkztw\n",
       "x733Ue/9ySRprX0gyZW99/+0gBlPuwN33Fp7bZK/leSvJeVPH1zdYf9fXJvk+iSfyO6zkJtbaxdP\n",
       "drwz4bAdJ8mjSX41u2eM/Lne+3MnOdxZ0Xu/N7tvGVxq4u7NO9KHnc/7uewO/IrNJM/OeZ6z6NBz\n",
       "prfWBq21jyf5E0n+1EkPd0YctuM/k+TVSf59kg8l+XOtte844fnOisP2/HSSz/beP9N7387us0G/\n",
       "aW9yB+64tfaHk3xzdt9GuC7Ja1prf/rEJzzbJu7evCN92Pm8H0vyta21a1prG9l9yv/wnOc5i8ad\n",
       "M/2ns/se1Lfve9mbyRy44977j/Xe39R7f1uSjyX5Z733n13MmKfeYX+XfzPJ+dba1+xdfkt2n/Ux\n",
       "mcN2/IUkX0zyUu99lOS3svvSN9O79NW1ibs319OC7juS8A17V703yTdk92XXT7bWvjm7LxUOktzl\n",
       "SMLJHbbj7L5s9StJHty7bZTkR3vv//ak5zzNxv093vd1fyFJc3T3dI7w/8XFJP9g77b/2nv/3pOf\n",
       "8nQ7wo6/K8lfzO7xLL+R5H17r1wwodbaVyf55733G/Y+ZTNV95y7GwCKcjITAChKpAGgKJEGgKJE\n",
       "GgCKEmkAKEqkAaAokQaAov4f7Z8nVt6qfgMAAAAASUVORK5CYII=\n"
      ],
      "text/plain": [
       "<matplotlib.figure.Figure at 0x107ae9828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from seaborn import distplot\n",
    "\n",
    "distplot(samples, kde=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a probabilistic programming framework, we would be able to assign a beta distribution to a particular parameter, and combine it with other parameters and data in order to provide inference.\n",
    "\n",
    "Python is not by itself a probabilistic language, but the PyMC package provides this functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pymc import Beta\n",
    "\n",
    "rate = Beta('rate', alpha=1, beta=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyMC includes classes of objects that represent most of the common statistical distributions. We can create variables representing these probabilities by passing it a name and the appropriate parameters.\n",
    "\n",
    "The `rate` object above is now an *instance* of a stochastic random variable that follows a beta distribution. It is given a value (drawn randomly if none is specified):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.8425899166032903)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rate.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can sample new values from it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.013788704130416995"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rate.random()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can obtain the log-probability of the current value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.440892098500626e-16"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rate.logp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most importantly, `rate` can be combined with other stochastic variables to specify a particular model. All PyMC objects will have **parents** that partly determine its value, in this case these are the beta parameters `alpha` and `beta` that were both assigned values of one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 1, 'beta': 1}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rate.parents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `parents` are stored in another standard Python data structure, called a `dictionary`. Dictionaries are sets of key-value pairs, for which the keys can be used to retrieve their corresponding values. So, if we want the value for a particular parent, we just index it by name (rather than by an array index)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rate.parents['beta']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables sometimes have **children** that, in turn, depend on their values. We have not specified any such relationship for `rate`, so it is just an empty set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rate.children"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `set` is yet another data structure that is like a dictionary, but consists only of values, and no corresponding keys."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we build a model with these components? Continuing with this simple example, we may want to use our `rate` object as a prior for an unknown rate that we wish to estimate. For example, we may want to estimate the mortality rate in the first hospital in our dataset.\n",
    "\n",
    "There were zero deaths in 47 operations. A natural model for this type of **bounded count** data is a binomial distribution. So, we can use the `Binomial` class in PyMC to model the data from one hostpital. \n",
    "\n",
    "Let's use the `help` function to get the documentation for `Binomial`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Binomial in module pymc.distributions:\n",
      "\n",
      "class Binomial(pymc.PyMCObjects.Stochastic)\n",
      " |  B = Binomial(name, n, p, value=None, observed=False, size=1, trace=True, rseed=True, doc=None, verbose=-1, debug=False)\n",
      " |  \n",
      " |  Stochastic variable with Binomial distribution.\n",
      " |  Parents are: n, p.\n",
      " |  \n",
      " |  Docstring of log-probability function:\n",
      " |  \n",
      " |      Binomial log-likelihood.  The discrete probability distribution of the\n",
      " |      number of successes in a sequence of n independent yes/no experiments,\n",
      " |      each of which yields success with probability p.\n",
      " |  \n",
      " |      .. math::\n",
      " |          f(x \\mid n, p) = \\frac{n!}{x!(n-x)!} p^x (1-p)^{n-x}\n",
      " |  \n",
      " |      :Parameters:\n",
      " |        - `x` : [int] Number of successes, > 0.\n",
      " |        - `n` : [int] Number of Bernoulli trials, > x.\n",
      " |        - `p` : Probability of success in each trial, :math:`p \\in [0,1]`.\n",
      " |  \n",
      " |      .. note::\n",
      " |         - :math:`E(X)=np`\n",
      " |         - :math:`Var(X)=np(1-p)`\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Binomial\n",
      " |      pymc.PyMCObjects.Stochastic\n",
      " |      pymc.Node.StochasticBase\n",
      " |      pymc.six.NewBase\n",
      " |      pymc.Node.Variable\n",
      " |      pymc.Node.Node\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, *args, **kwds)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  dtype = <class 'int'>\n",
      " |      int(x=0) -> integer\n",
      " |      int(x, base=10) -> integer\n",
      " |      \n",
      " |      Convert a number or string to an integer, or return 0 if no arguments\n",
      " |      are given.  If x is a number, return x.__int__().  For floating point\n",
      " |      numbers, this truncates towards zero.\n",
      " |      \n",
      " |      If x is not a number or if base is given, then x must be a string,\n",
      " |      bytes, or bytearray instance representing an integer literal in the\n",
      " |      given base.  The literal can be preceded by '+' or '-' and be surrounded\n",
      " |      by whitespace.  The base defaults to 10.  Valid bases are 0 and 2-36.\n",
      " |      Base 0 means to interpret the base from the string as an integer literal.\n",
      " |      >>> int('0b100', base=0)\n",
      " |      4\n",
      " |  \n",
      " |  mv = False\n",
      " |  \n",
      " |  parent_names = ['n', 'p']\n",
      " |  \n",
      " |  parents_default = {}\n",
      " |  \n",
      " |  raw_fns = {'logp': <function valuewrapper.<locals>.wrapper>, 'random':...\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pymc.PyMCObjects.Stochastic:\n",
      " |  \n",
      " |  gen_lazy_function(self)\n",
      " |      Will be called by Node at instantiation.\n",
      " |  \n",
      " |  get_logp(self)\n",
      " |  \n",
      " |  get_stoch_value(self)\n",
      " |  \n",
      " |  get_value(self)\n",
      " |  \n",
      " |  logp_gradient_contribution(self, calculation_set=None)\n",
      " |      Calculates the gradient of the joint log posterior with respect to self.\n",
      " |      Calculation of the log posterior is restricted to the variables in calculation_set.\n",
      " |  \n",
      " |  logp_partial_gradient(self, variable, calculation_set=None)\n",
      " |      Calculates the partial gradient of the posterior of self with respect to variable.\n",
      " |      Returns zero if self is not in calculation_set.\n",
      " |  \n",
      " |  rand = random(self)\n",
      " |      Draws a new value for a stoch conditional on its parents\n",
      " |      and returns it.\n",
      " |      \n",
      " |      Raises an error if no 'random' argument was passed to __init__.\n",
      " |  \n",
      " |  random(self)\n",
      " |      Draws a new value for a stoch conditional on its parents\n",
      " |      and returns it.\n",
      " |      \n",
      " |      Raises an error if no 'random' argument was passed to __init__.\n",
      " |  \n",
      " |  revert(self)\n",
      " |      Sets self's value to self's last value. Bypasses the data cleaning in\n",
      " |      the set_value method.\n",
      " |  \n",
      " |  set_logp(self, new_logp)\n",
      " |  \n",
      " |  set_value(self, value, force=False)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pymc.PyMCObjects.Stochastic:\n",
      " |  \n",
      " |  coparents\n",
      " |      All the variables whose extended children intersect with self's.\n",
      " |  \n",
      " |  isdata\n",
      " |  \n",
      " |  logp\n",
      " |      Log-probability or log-density of self's current value\n",
      " |      given values of parents.\n",
      " |  \n",
      " |  markov_blanket\n",
      " |      Self's coparents, self's extended parents, self's children and self.\n",
      " |  \n",
      " |  mask\n",
      " |      Returns the mask for missing values\n",
      " |  \n",
      " |  moral_neighbors\n",
      " |      Self's neighbors in the moral graph: self's Markov blanket with self removed.\n",
      " |  \n",
      " |  observed\n",
      " |  \n",
      " |  shape\n",
      " |      The shape of the value of self.\n",
      " |  \n",
      " |  value\n",
      " |      Self's current value.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from pymc.PyMCObjects.Stochastic:\n",
      " |  \n",
      " |  __array_priority__ = 1000\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pymc.Node.Variable:\n",
      " |  \n",
      " |  __abs__(self)\n",
      " |  \n",
      " |  __add__(self, other, prefix='')\n",
      " |  \n",
      " |  __and__(self, other, prefix='')\n",
      " |  \n",
      " |  __call__(self, *args, **kwargs)\n",
      " |  \n",
      " |  __complex__(self, op=<class 'complex'>)\n",
      " |  \n",
      " |  __divmod__(self, other, prefix='')\n",
      " |  \n",
      " |  __float__(self, op=<class 'float'>)\n",
      " |  \n",
      " |  __floordiv__(self, other, prefix='')\n",
      " |  \n",
      " |  __ge__(self, other)\n",
      " |  \n",
      " |  __getitem__(self, index)\n",
      " |      # Create __getitem__ method.\n",
      " |  \n",
      " |  __gt__(self, other)\n",
      " |  \n",
      " |  __hex__(self, op=<built-in function hex>)\n",
      " |  \n",
      " |  __iadd__(self, *args)\n",
      " |  \n",
      " |  __iand__(self, *args)\n",
      " |  \n",
      " |  __idiv__(self, *args)\n",
      " |  \n",
      " |  __ifloordiv__(self, *args)\n",
      " |  \n",
      " |  __ilshift__(self, *args)\n",
      " |  \n",
      " |  __imod__(self, *args)\n",
      " |  \n",
      " |  __imul__(self, *args)\n",
      " |  \n",
      " |  __int__(self, op=<class 'int'>)\n",
      " |  \n",
      " |  __invert__(self)\n",
      " |  \n",
      " |  __ior__(self, *args)\n",
      " |  \n",
      " |  __ipow__(self, *args)\n",
      " |  \n",
      " |  __irshift__(self, *args)\n",
      " |  \n",
      " |  __isub__(self, *args)\n",
      " |  \n",
      " |  __iter__(self, op=<built-in function iter>)\n",
      " |  \n",
      " |  __itruediv__(self, *args)\n",
      " |  \n",
      " |  __ixor__(self, *args)\n",
      " |  \n",
      " |  __le__(self, other)\n",
      " |  \n",
      " |  __lshift__(self, other, prefix='')\n",
      " |  \n",
      " |  __lt__(self, other)\n",
      " |  \n",
      " |  __mod__(self, other, prefix='')\n",
      " |  \n",
      " |  __mul__(self, other, prefix='')\n",
      " |  \n",
      " |  __ne__(self, other)\n",
      " |  \n",
      " |  __neg__(self)\n",
      " |  \n",
      " |  __oct__(self, op=<built-in function oct>)\n",
      " |  \n",
      " |  __or__(self, other, prefix='')\n",
      " |  \n",
      " |  __pow__(self, other, prefix='')\n",
      " |  \n",
      " |  __radd__(self, other, prefix='r')\n",
      " |  \n",
      " |  __rand__(self, other, prefix='r')\n",
      " |  \n",
      " |  __rdivmod__(self, other, prefix='r')\n",
      " |  \n",
      " |  __rfloordiv__(self, other, prefix='r')\n",
      " |  \n",
      " |  __rlshift__(self, other, prefix='r')\n",
      " |  \n",
      " |  __rmod__(self, other, prefix='r')\n",
      " |  \n",
      " |  __rmul__(self, other, prefix='r')\n",
      " |  \n",
      " |  __ror__(self, other, prefix='r')\n",
      " |  \n",
      " |  __rpow__(self, other, prefix='r')\n",
      " |  \n",
      " |  __rrshift__(self, other, prefix='r')\n",
      " |  \n",
      " |  __rshift__(self, other, prefix='')\n",
      " |  \n",
      " |  __rsub__(self, other, prefix='r')\n",
      " |  \n",
      " |  __rtruediv__(self, other, prefix='r')\n",
      " |  \n",
      " |  __rxor__(self, other, prefix='r')\n",
      " |  \n",
      " |  __str__(self)\n",
      " |  \n",
      " |  __sub__(self, other, prefix='')\n",
      " |  \n",
      " |  __truediv__(self, other, prefix='')\n",
      " |  \n",
      " |  __xor__(self, other, prefix='')\n",
      " |  \n",
      " |  stats(self, alpha=0.05, start=0, batches=100, chain=None, quantiles=(2.5, 25, 50, 75, 97.5))\n",
      " |      Generate posterior statistics for node.\n",
      " |      \n",
      " |      :Parameters:\n",
      " |      alpha : float\n",
      " |        The alpha level for generating posterior intervals. Defaults to\n",
      " |        0.05.\n",
      " |      \n",
      " |      start : int\n",
      " |        The starting index from which to summarize (each) chain. Defaults\n",
      " |        to zero.\n",
      " |      \n",
      " |      batches : int\n",
      " |        Batch size for calculating standard deviation for non-independent\n",
      " |        samples. Defaults to 100.\n",
      " |      \n",
      " |      chain : int\n",
      " |        The index for which chain to summarize. Defaults to None (all\n",
      " |        chains).\n",
      " |      \n",
      " |      quantiles : tuple or list\n",
      " |        The desired quantiles to be calculated. Defaults to (2.5, 25, 50, 75, 97.5).\n",
      " |  \n",
      " |  summary(self, alpha=0.05, start=0, batches=100, chain=None, roundto=3)\n",
      " |      Generate a pretty-printed summary of the node.\n",
      " |      \n",
      " |      :Parameters:\n",
      " |      alpha : float\n",
      " |        The alpha level for generating posterior intervals. Defaults to\n",
      " |        0.05.\n",
      " |      \n",
      " |      start : int\n",
      " |        The starting index from which to summarize (each) chain. Defaults\n",
      " |        to zero.\n",
      " |      \n",
      " |      batches : int\n",
      " |        Batch size for calculating standard deviation for non-independent\n",
      " |        samples. Defaults to 100.\n",
      " |      \n",
      " |      chain : int\n",
      " |        The index for which chain to summarize. Defaults to None (all\n",
      " |        chains).\n",
      " |      \n",
      " |      roundto : int\n",
      " |        The number of digits to round posterior statistics.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pymc.Node.Variable:\n",
      " |  \n",
      " |  plot\n",
      " |      A flag indicating whether self should be plotted.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pymc.Node.Node:\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pymc.Node.Node:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  parents\n",
      " |      Self's parents: the variables referred to in self's declaration.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pymc import Binomial\n",
    "\n",
    "help(Binomial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This provides a lot of information about this stochastic. You can see that there is a list of arguments, some which are associated with assigned values, and others that do not have assigned values. The former are called *keyword* arguments, and are optional; if values are not provided by the user, then the values shown in the documentation are passed as *default* values. You can see here that only three variables are required: `name`, `n` (the sample size), and `p` (the probability of an event).\n",
    "\n",
    "We will use 47 for the sample size, `rate` as the probability (its true value is unknown), and 0 for the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = Binomial('d', n=47, p=rate, value=0, observed=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we inclued a fifth argument, `oberved=True`. This is used to recognize that the particular value of this variable was observed (*i.e.* it comes from our dataset) and should not be changed. As with `rate`, which is an unobserved variable, we can sample from `d` but the value does not change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now inspect some of the attributes of our variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{<pymc.distributions.new_dist_class.<locals>.new_class 'd' at 0x10e7edf28>}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rate.children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n': 47,\n",
       " 'p': <pymc.distributions.new_dist_class.<locals>.new_class 'rate' at 0x10c1f2a58>}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.parents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our very simple model, `rate` is the prior distribution of the unknown variable, and `d` is the likelihood that provides the information from the data.\n",
    "\n",
    "We can use one of several statistical methods to estimate the true value of `rate`. The simplest of these is the **maximum a posteriori (MAP)** estimate for the posterior. This simply uses optimization to seek out the value of `rate` that maximizes its posterior distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymc.NormalApproximation.MAP at 0x10e81bcf8>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pymc import MAP\n",
    "\n",
    "model = MAP([rate, d])\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have another PyMC object `MAP` that retains a method for fitting the unknown variables using MAP. We can initiate this using the `fit()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When `fit` has completed, the value of `rate` will now be the MAP estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(6.547924705230564e-12)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rate.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we might expect, the estimate is very close to zero!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Specify Probability Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Calculate Posterior Distribution of Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Check the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternatives\n",
    "\n",
    "* [WinBUGS](http://www.openbugs.net/w/FrontPage) or [JAGS](http://mcmc-jags.sourceforge.net)\n",
    "* [Stan](http://mc-stan.org)\n",
    "* SAS ([PROC MCMC](http://support.sas.com/documentation/cdl/en/statug/63033/HTML/default/viewer.htm#statug_mcmc_sect019.htm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliography\n",
    "\n",
    "+ Gelman A, Carlin JB, Stern HS, Dunson DB, Vehtari A, Rubin DB. Bayesian Data Analysis, Third Edition. CRC Press; 2013.\n",
    "+ Davidson-Pilon C, et al. [Probabilistic Programming & Bayesian Methods for Hackers](http://camdavidsonpilon.github.io/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        src: url('http://mirrors.ctan.org/fonts/cm-unicode/fonts/otf/cmunss.otf');\n",
       "    }\n",
       "    div.cell{\n",
       "        width: 90%;\n",
       "/*        margin-left:auto;*/\n",
       "/*        margin-right:auto;*/\n",
       "    }\n",
       "    ul {\n",
       "        line-height: 145%;\n",
       "        font-size: 90%;\n",
       "    }\n",
       "    li {\n",
       "        margin-bottom: 1em;\n",
       "    }\n",
       "    h1 {\n",
       "        font-family: Helvetica, serif;\n",
       "    }\n",
       "    h4{\n",
       "        margin-top: 12px;\n",
       "        margin-bottom: 3px;\n",
       "       }\n",
       "    div.text_cell_render{\n",
       "        font-family: Computer Modern, \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;\n",
       "        line-height: 145%;\n",
       "        font-size: 150%;\n",
       "        width: 90%;\n",
       "        margin-left:auto;\n",
       "        margin-right:auto;\n",
       "    }\n",
       "    .CodeMirror{\n",
       "            font-family: \"Source Code Pro\", source-code-pro,Consolas, monospace;\n",
       "    }\n",
       "/*    .prompt{\n",
       "        display: None;\n",
       "    }*/\n",
       "    .text_cell_render h5 {\n",
       "        font-weight: 300;\n",
       "        font-size: 16pt;\n",
       "        color: #4057A1;\n",
       "        font-style: italic;\n",
       "        margin-bottom: 0.5em;\n",
       "        margin-top: 0.5em;\n",
       "        display: block;\n",
       "    }\n",
       "\n",
       "    .warning{\n",
       "        color: rgb( 240, 20, 20 )\n",
       "        }\n",
       "</style>\n",
       "<script>\n",
       "    MathJax.Hub.Config({\n",
       "                        TeX: {\n",
       "                           extensions: [\"AMSmath.js\"]\n",
       "                           },\n",
       "                tex2jax: {\n",
       "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n",
       "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n",
       "                },\n",
       "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
       "                \"HTML-CSS\": {\n",
       "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
       "                }\n",
       "        });\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "def css_styling():\n",
    "    styles = open(\"styles/custom.css\", \"r\").read()\n",
    "    return HTML(styles)\n",
    "css_styling()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
